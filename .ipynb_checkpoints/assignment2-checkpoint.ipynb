{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layers    N images -> C images, filter window size KxK\n",
    "# Maxpooling operations   Reduce feature map dimensions by picking max value within local, non-overlapping slides size LxL\n",
    "# Fully connected layers  N output units connected to each of the M input units\n",
    "# PyTorch : Python package for replacing NumPy with GPUs or deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3556e-19, 1.3563e-19, 1.3563e-19],\n",
      "        [1.8561e-19, 1.4584e-19, 7.8454e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19],\n",
      "        [1.8561e-19, 1.4584e-19, 7.8456e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19]])\n",
      "<built-in method type of Tensor object at 0x7f167bc766c0>\n"
     ]
    }
   ],
   "source": [
    "# Values randomly initialized between 0-1\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "print(x.type)\n",
    "# The type is Tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8826, 0.3274, 0.4059],\n",
      "        [0.7696, 0.6767, 0.7296],\n",
      "        [0.0667, 0.4313, 0.5174],\n",
      "        [0.7244, 0.4422, 0.3365],\n",
      "        [0.7302, 0.7722, 0.6827]])\n",
      "<built-in method type of Tensor object at 0x7f167bc6e1b0>\n",
      "tensor([[ 1.5571,  1.8023, -0.6375],\n",
      "        [-1.4384,  1.4147, -1.4743],\n",
      "        [-2.3142, -0.9183, -1.3612],\n",
      "        [ 0.6927,  1.1305, -0.2529],\n",
      "        [-2.3846, -0.4954,  0.6530]])\n"
     ]
    }
   ],
   "source": [
    "# Random numbers within range 0-1\n",
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(y.type)\n",
    "# The type is Tensor object\n",
    "\n",
    "# Random numbers within range 0-1 with mean 0 std 1\n",
    "y = torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3556e-19, 1.3563e-19, 1.3563e-19],\n",
      "        [1.8561e-19, 1.4584e-19, 7.8454e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19],\n",
      "        [1.8561e-19, 1.4584e-19, 7.8456e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19]], dtype=torch.float64)\n",
      "tensor([[ 1.5571,  1.8023, -0.6375],\n",
      "        [-1.4384,  1.4147, -1.4743],\n",
      "        [-2.3142, -0.9183, -1.3612],\n",
      "        [ 0.6927,  1.1305, -0.2529],\n",
      "        [-2.3846, -0.4954,  0.6530]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)\n",
    "# The type is torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859,  1.3970,  0.5236],\n",
    "                  [ 2.3854,  0.0707,  2.1970],\n",
    "                  [-0.3587,  1.2359,  1.8951],\n",
    "                  [-0.1189, -0.1376,  0.4647],\n",
    "                  [-1.8968,  2.0164,  0.1092]])\n",
    "y = torch.Tensor([[ 0.4838,  0.5822,  0.2755],\n",
    "                  [ 1.0982,  0.4932, -0.6680],\n",
    "                  [ 0.7915,  0.6580, -0.5819],\n",
    "                  [ 0.3825, -1.1822,  1.5217],\n",
    "                  [ 0.6042, -0.2280,  1.3210]])\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x, y))   # stack entire matrices\n",
    "print(z.shape)\n",
    "z1 = torch.cat((x, y), 0) # stack alone columns\n",
    "print(z1.shape)\n",
    "z2 = torch.cat((x, y), 1) # stack along rows\n",
    "print(z2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])\n",
    "print(z[1,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1092, 1.3210])\n"
     ]
    }
   ],
   "source": [
    "print(z[:,4,2]) # There are two elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "# 3 ways to sum x and y\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshape a tensor\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # -1 is unsure of number of rows\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-16.0412,  -3.1227]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 10)\n",
    "y = torch.randn(2, 100)\n",
    "x = x.view(1, 100)\n",
    "y = y.view(100, 2)\n",
    "z = torch.mm(x, y)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<built-in method type of Tensor object at 0x7f167bc8cab0>\n",
      "[1. 1. 1. 1. 1.]\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5) # type tensor([])\n",
    "print(a)\n",
    "print(a.type)\n",
    "b = a.numpy()     # type []\n",
    "print(b)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor and numpy array share same memory location\n",
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.])\n",
      "tensor([4., 3., 3., 3., 3.])\n",
      "tensor([5., 4., 4., 4., 4.])\n"
     ]
    }
   ],
   "source": [
    "# 3 ways to add 1 to first index\n",
    "a.add_(1)\n",
    "print(a)\n",
    "a[:] += 1\n",
    "print(a)\n",
    "a = a.add(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy array to tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Move tensor onto GPU device's memory .to('cuda') or .cuda()\n",
    "# Move tensor back to CPU device .to('cpu') or .cpu()\n",
    "# or allocate tensor directly to GPU using device optional argument\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "x = torch.randn(5, 3).to(device)\n",
    "y = torch.randn(5, 3, device=device)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6564677  -1.0184641  -0.02946806]\n",
      " [-0.5212628   0.16838968 -2.1205254 ]\n",
      " [-1.0580049  -0.46218944 -3.1883717 ]\n",
      " [-1.7098668  -0.27525604  1.6873641 ]\n",
      " [-0.45054054 -0.46416646 -0.03061628]]\n",
      "<built-in method numpy of Tensor object at 0x7f167bc8ca20>\n"
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# requires_grad is set to False by default setting it True tracks all operations where the tensor is \n",
    "# involved when computation complete, call .backward() to have all gradients computed automatically for \n",
    "# all these tensors. Gradients for these tensors accumulated into .grad attribute\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y) \n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3e45dac8022c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "z = y * y * 3 \n",
    "# = 3*(x+2)^2 \n",
    "# = (3*(x1+2)^2 + 3*(x2+2)^2 + 3*(x3+2)^2 + 3*(x4+2)^2) / 4\n",
    "# df/dx1 = 3*2(x1+2)/4 = ((6*x1)+12) / 4\n",
    "# x1 = 1\n",
    "# df/dx1 = (6+12)/4 = 18/4 = 4.5\n",
    "f = z.mean()\n",
    "print(z,f)\n",
    "\n",
    "b = x1\n",
    "a = x1*x2*b\n",
    "f = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.grad_fn)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools\n",
    "\n",
    "# Images stacked in columns\n",
    "# Vector of corresponding labels from 0 to 9\n",
    "xtrain, ltrain = MNISTtools.load(\"training\", path=\"./mnist/\")\n",
    "xtest, ltest = MNISTtools.load(\"testing\", path=\"./mnist/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    x = ((x-255.0/2)/(255.0/2))\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "print(np.min(xtrain))\n",
    "print(np.max(xtrain))\n",
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "xtest = normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 60000)\n",
      "(28, 28, 1, 10000)\n",
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "xtrain = xtrain.reshape(28, 28, 1, 60000)\n",
    "xtest = xtest.reshape(28, 28, 1, 10000)\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "xtrain = np.moveaxis(xtrain, -1, 0)\n",
    "xtrain = np.moveaxis(xtrain, -1, 1)\n",
    "xtest = np.moveaxis(xtest, -1, 0)\n",
    "xtest = np.moveaxis(xtest, -1, 1)\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAADL5JREFUeJzt3W+oXAV+xvHncTe+MIkxkptssNrbSl60FDYpg1StJbJ0sQv+e+FqxCWBZeOLFSou+PeFeWFFyurWF0WITdgbMLaCWgNKupIU7L4JOwnRZBvbXZZbm9zLzQSFGAgpMb++uCfb23jnzDhzzpzJ/r4fCHfm/M7JPJzkuWdmzvxxRAhAPlc0HQBAMyg/kBTlB5Ki/EBSlB9IivIDSTVSftt32P4P27+2/WQTGbqxPW37iO3DttsNZ9lp+6TtowuWXWv7fdu/Kn6uHKNs22yfKPbdYdvfaSjb9bb/1fYx27+0/dfF8kb3XUmuRvabR32e3/bXJP2npL+UdFzSLyRtioh/H2mQLmxPS2pFxKkxyPIXks5I2hURf1Is+1tJn0bEC8UvzpUR8cSYZNsm6UxE/HjUeS7JtlbS2og4ZHu5pIOS7pG0RQ3uu5Jc31UD+62JI/9Nkn4dEb+JiP+R9I+S7m4gx9iLiA8kfXrJ4rslTRWXpzT/n2fkumQbCxExGxGHisufSzom6To1vO9KcjWiifJfJ+m/F1w/rgZ3wCJC0s9sH7S9tekwi1gTEbPS/H8mSasbznOpR2x/VDwsaOQhyUK2JyVtkHRAY7TvLsklNbDfmii/F1k2Tq8xvjUi/lTSX0n6YXH3Fv15RdKNktZLmpX0YpNhbC+T9KakRyPidJNZFlokVyP7rYnyH5d0/YLrvydppoEci4qImeLnSUlva/5hyjiZKx47XnwMebLhPL8VEXMR8UVEXJD0qhrcd7aXaL5gr0XEW8XixvfdYrma2m9NlP8XktbZ/gPbV0p6QNKeBnJ8ie2lxRMxsr1U0rclHS3fauT2SNpcXN4s6Z0Gs/w/F4tVuFcN7TvblrRD0rGIeGnBqNF91y1XU/tt5M/2S1JxKuPvJH1N0s6I+JuRh1iE7T/U/NFekr4uaXeT2Wy/LmmjpFWS5iQ9K+mfJb0h6QZJn0i6LyJG/sRbl2wbNX/XNSRNS3r44mPsEWf7c0n/JumIpAvF4qc1//i6sX1XkmuTGthvjZQfQPN4hR+QFOUHkqL8QFKUH0iK8gNJNVr+MX35rKTxzTauuSSyDaqpbE0f+cf2H0Tjm21cc0lkG1TK8gNoyFAv8rF9h6SXNf9KvX+IiBfK1l+1alVMTk7+9nqn09HExMTAt1+ncc02rrkksg2qymzT09M6derUYm+e+5KvD3ojxYdy/L0WfCiH7T1lH8oxOTmpdrvRD8cBfqe1Wq2+1x3mbj8fygFcxoYp/7h/KAeAEsOUv68P5bC91XbbdrvT6QxxcwCqNEz5+/pQjojYHhGtiGiN6xMuQEbDlH9sP5QDQG8DP9sfEedtPyLpX/R/H8rxy8qSAajVwOWXpIh4T9J7FWUBMEK8wg9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkqL8QFKUH0iK8gNJUX4gKcoPJEX5gaQoP5AU5QeSovxAUpQfSIryA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+Q1FBf0W17WtLnkr6QdD4iWlWEAlC/ocpfuD0iTlXw9wAYIe72A0kNW/6Q9DPbB21vrSIQgNEY9m7/rRExY3u1pPdtfxwRHyxcofilsFWSbrjhhiFvDkBVhjryR8RM8fOkpLcl3bTIOtsjohURrYmJiWFuDkCFBi6/7aW2l1+8LOnbko5WFQxAvYa5279G0tu2L/49uyNibyWpANRu4PJHxG8kfbPCLABGiFN9QFKUH0iK8gNJUX4gKcoPJFXFG3twGYuI0vmZM2dK53v3lp/d3bVrV9fZhx9+WLrtkSNHSucrVqwonaMcR34gKcoPJEX5gaQoP5AU5QeSovxAUpQfSIrz/L8DTp8+3XW2f//+0m137NhROn/33XcHytSPpUuXls6XLFlS222DIz+QFuUHkqL8QFKUH0iK8gNJUX4gKcoPJMV5/jEwMzNTOn/++edL52Xn6s+dO1e67bp160rn27ZtK52fP3++dP7cc891nd1///2l21511VWlcwyHIz+QFOUHkqL8QFKUH0iK8gNJUX4gKcoPJMV5/gp8/PHHpfO77rqrdH7ixInS+dmzZ0vnTz31VNfZli1bSrednJwsnfd6T32v7GXn+Tds2FC6LerV88hve6ftk7aPLlh2re33bf+q+Lmy3pgAqtbP3f6fSrrjkmVPStoXEesk7SuuA7iM9Cx/RHwg6dNLFt8taaq4PCXpnopzAajZoE/4rYmIWUkqfq7utqLtrbbbttudTmfAmwNQtdqf7Y+I7RHRiojWxMRE3TcHoE+Dln/O9lpJKn6erC4SgFEYtPx7JG0uLm+W9E41cQCMSs/z/LZfl7RR0irbxyU9K+kFSW/Y/r6kTyTdV2fIcffZZ5+Vzm+77bbS+bJly0rnDz30UOm81Wp1ndku3bZJvT63H/XqWf6I2NRl9K2KswAYIV7eCyRF+YGkKD+QFOUHkqL8QFK8pbcCN99881Dzy9kTTzwx8LYPPPBAhUnwVXHkB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkOM+PoUxPTzcdAQPiyA8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSXGeH7W6/fbbu86uvPLKESbBpTjyA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSnOdHqdOnT5fODx48WDrfsmVL19kVV3DsaVLPvW97p+2Tto8uWLbN9gnbh4s/36k3JoCq9fOr96eS7lhk+U8iYn3x571qYwGoW8/yR8QHkj4dQRYAIzTMg65HbH9UPCxY2W0l21ttt223O53OEDcHoEqDlv8VSTdKWi9pVtKL3VaMiO0R0YqI1sTExIA3B6BqA5U/IuYi4ouIuCDpVUk3VRsLQN0GKr/ttQuu3ivpaLd1AYynnuf5bb8uaaOkVbaPS3pW0kbb6yWFpGlJD9eYEQ3av39/6fzcuXOl88cee6zKOKhQz/JHxKZFFu+oIQuAEeIlVkBSlB9IivIDSVF+ICnKDyTFW3pRat++faXzXm/LXb16dZVxUCGO/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+QFOf5UWpmZqZ0fsstt5TOV6xYUWUcVIgjP5AU5QeSovxAUpQfSIryA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnKDyTVz1d0Xy9pl6RvSLogaXtEvGz7Wkn/JGlS81/T/d2I+Ky+qKhDr6/Y3rt3b+n8zjvvrDIORqifI/95ST+KiD+S9GeSfmj7jyU9KWlfRKyTtK+4DuAy0bP8ETEbEYeKy59LOibpOkl3S5oqVpuSdE9dIQFU7ys95rc9KWmDpAOS1kTErDT/C0IS38sEXEb6Lr/tZZLelPRoRJz+Cttttd223e50OoNkBFCDvspve4nmi/9aRLxVLJ6zvbaYr5V0crFtI2J7RLQiojUxMVFFZgAV6Fl+25a0Q9KxiHhpwWiPpM3F5c2S3qk+HoC69PPR3bdK+p6kI7YPF8uelvSCpDdsf1/SJ5Luqyci6nTgwIHS+dmzZ0vnjz/+eJVxMEI9yx8RP5fkLuNvVRsHwKjwCj8gKcoPJEX5gaQoP5AU5QeSovxAUnxFd3JTU1O9VyqxZs2aipJg1DjyA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSnOdHqWuuuaZ0fvXVV48oCarGkR9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkuI8f3KHDh0qnff6lqXly5dXGQcjxJEfSIryA0lRfiApyg8kRfmBpCg/kBTlB5LqeZ7f9vWSdkn6hqQLkrZHxMu2t0n6gaROserTEfFeXUExmN27d5fODx8+XDp/5plnqoyDMdLPi3zOS/pRRByyvVzSQdvvF7OfRMSP64sHoC49yx8Rs5Jmi8uf2z4m6bq6gwGo11d6zG97UtIGSQeKRY/Y/sj2TtsrK84GoEZ9l9/2MklvSno0Ik5LekXSjZLWa/6ewYtdtttqu2273el0FlsFQAP6Kr/tJZov/msR8ZYkRcRcRHwRERckvSrppsW2jYjtEdGKiFavN4kAGJ2e5bdtSTskHYuIlxYsX7tgtXslHa0+HoC69PNs/62SvifpiO2L54WelrTJ9npJIWla0sO1JMRQ5ubmhtr+wQcfrCgJxk0/z/b/XJIXGXFOH7iM8Qo/ICnKDyRF+YGkKD+QFOUHkqL8QFKOiJHdWKvVina7PbLbA7JptVpqt9uLnZr/Eo78QFKUH0iK8gNJUX4gKcoPJEX5gaQoP5DUSM/z2+5I+q+R3SCQz+9HRF8fmTXS8gMYH9ztB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkvpfNsSHVlloACgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check data is well organized by displaying digit that corresponds to ltrain[42].\n",
    "MNISTtools.show(xtrain[42, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) for MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)   # 4*4*16\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # Here we define one forward pass through the network\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f16701ef6d8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return learnable parameters of the model\n",
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9200)\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass of initial network over testing set\n",
    "with torch.no_grad():\n",
    "    yinit = net(xtest)\n",
    "\n",
    "# Percentage accuracy\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.303\n",
      "[2,   100] loss: 2.298\n",
      "[3,   100] loss: 2.293\n"
     ]
    }
   ],
   "source": [
    "# Mini-Batch Stochastic Gradient Descent with cross-entropy and momentum\n",
    "# T (num of epochs), B (minibatch size), gamma (step size), rho(momentum)\n",
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]     # Training set size\n",
    "    NB = B                   # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            inputs = xtrain[minibatch_indices,:,:,:]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.3300)\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass of network over testing set\n",
    "ytest = net(xtest)\n",
    "\n",
    "# Percentage accuracy\n",
    "_, lpred = ytest.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Move the training data to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "xtrain = xtrain.to(device)\n",
    "ltrain = ltrain.to(device)\n",
    "xtest  = xtest.to(device)\n",
    "ltest  = ltest.to(device)\n",
    "\n",
    "# Reinitialize new network and transfer it to GPU\n",
    "net = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.302\n",
      "[2,   100] loss: 2.292\n",
      "[3,   100] loss: 2.278\n",
      "[4,   100] loss: 2.255\n",
      "[5,   100] loss: 2.210\n",
      "[6,   100] loss: 2.079\n",
      "[7,   100] loss: 1.670\n",
      "[8,   100] loss: 1.000\n",
      "[9,   100] loss: 0.603\n",
      "[10,   100] loss: 0.472\n"
     ]
    }
   ],
   "source": [
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87.0900, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass of network over testing set\n",
    "with torch.no_grad():\n",
    "    ytest = net(xtest)\n",
    "\n",
    "# Percentage accuracy\n",
    "_, lpred = ytest.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
